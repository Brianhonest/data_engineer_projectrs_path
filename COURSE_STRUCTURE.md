# NY Taxi Data Pipeline Course

## Course Structure

This repository is organized by weeks to track progress through the data engineering course.

### Week 1: Basics and Setup
- **Focus**: Development environment setup and basic tools
- **Topics**: Terraform, Docker, PostgreSQL
- **Status**: üîÑ In Progress

### Week 2: Workflow Orchestration  
- **Focus**: Data pipeline orchestration tools
- **Topics**: Airflow, Prefect, workflow management
- **Status**: ‚è≥ Pending

### Week 3: Data Warehouse
- **Focus**: Data warehousing concepts and implementation
- **Topics**: BigQuery, data modeling, ETL
- **Status**: ‚è≥ Pending

### Week 4: Analytics Engineering
- **Focus**: dbt and analytics engineering practices
- **Topics**: dbt, data transformation, testing
- **Status**: ‚è≥ Pending

### Week 5: Batch Processing
- **Focus**: Large-scale data processing
- **Topics**: Spark, batch processing patterns
- **Status**: ‚è≥ Pending

### Week 6: Streaming
- **Focus**: Real-time data processing
- **Topics**: Kafka, streaming architectures
- **Status**: ‚è≥ Pending

## How to Use This Repository

1. **Weekly Progress**: Each week has its own folder with dedicated READMEs
2. **Commit Often**: Make frequent commits to track your learning progress
3. **Document Everything**: Use the README files to document your learnings and notes
4. **Organize by Activity**: Each week has subfolders for different activities (homework, projects, etc.)

## Getting Started

1. Navigate to the current week's folder
2. Read the weekly README for objectives and activities
3. Complete activities in the appropriate subfolders
4. Document your progress and learnings
5. Commit and push changes regularly

## Course Progress Tracking

- [ ] Week 1: Basics and Setup
- [ ] Week 2: Workflow Orchestration
- [ ] Week 3: Data Warehouse
- [ ] Week 4: Analytics Engineering
- [ ] Week 5: Batch Processing
- [ ] Week 6: Streaming